a=c(1,2,3,4)
median(a)
med(Boston$ptratio)
median(Boston$ptratio)
summary(Boston$ptratio)
?Boston
summary(Boston$medv)
Boston[Boston$medv=min(Boston$medv)]
Boston[Boston$medv=min(Boston$medv),]
Boston[Boston$medv==min(Boston$medv),]
summary(Boston$lstat)
summary(Boston$black)
summary(Boston$tax)
summary(Boston$crim)
mean(a)
a=c(1,2,3,8,7)
mean(a)
median(a)
a=c(1,2,3,8,7,9)
mean(a)
median(a)
Boston[Boston$rm>7,]
count(Boston[Boston$rm>7,])
cnt(Boston[Boston$rm>7,])
nrow(Boston[Boston$rm>7,])
nrow(Boston[Boston$rm>8,])
(Boston[Boston$rm>8,])
summary(Boston$crim)
savehistory()
summary(Boston$crim)
library(MASS)
library(ISLR)
install.packages("ISLR")
?Boston
fix(Boston)
fix(Boston)
?fix
names(Boston)
?Boston
lm.fit=lm(med~lstat)
lm.fit=lm(med~lstat,data=Boston)
lm.fit=lm(medv~lstat,data=Boston)
lm.fit
summary(lm.fit)
lm.fit$coefficients
names(lm.fit)
coef(lm.fit)
confint(lm.fit)
?Boston
Boston$lstat[1,1]
Boston$lstat[1]
predict(lm.fit,data.frame(lstat=c(5,10,15))),interval="confidence")
predict(lm.fit,data.frame(lstat=(c(5,10,15))),interval="confidence")
summary(boston?medv)
summary(Boston?medv)
summary(Boston$medv)
summary(Boston$lstat)
install.packages("ISLR")
plot(Boston$medv,Boston$lstat)
?Boston
plot(Boston$lstat,Boston$medv)
abline(lm.fit)
abline(lm.fit,lwd=3)
abline(lm.fit,lwd=3,col="red")
plot(Boston$lstat,Boston$medv,col="red")
plot(Boston$lstat,Boston$medv,pch=20)
plot(Boston$lstat,Boston$medv,pch="+")
plot(Boston$lstat,Boston$medv,pch="*")
plot(Boston$lstat,Boston$medv,pch="R")
plot(Boston$lstat,Boston$medv,pch="/")
plot (1:20,1:20,pch=1:20)
par(mfrow=c(2,2))
plot(lm.fit)
plot(predict(lm.fit),residuals(lm.fit))
plot(predict(lm.fit),restudent(lm.fit))
plot(predict(lm.fit),rstudent(lm.fit))
plot(hatvalues(lm.fit))
which.max(plot(hatvalues(lm.fit)))
which.max(hatvalues(lm.fit))
21126909
8663166526
savehistory()
exit
quit
quit
quit()
library(MASS)
quit()
etf = "http://finance.yahoo.com/etf/lists/category/"
etf.table= readHTMLTable(etf)
library(XML)
etf.table= readHTMLTable(etf)
etf.table
str(etf.table)
etf = "finance.yahoo.com/etf/lists/category/"
etf.table= readHTMLTable(etf)
etf = "http://finance.yahoo.com/etf/lists/category/"
etf.table= readHTMLTable(etf)
u = "http://en.wikipedia.org/wiki/List_of_countries_by_population"
tables = readHTMLTable(u)
tables
names(tables)
tables[[2]]
tmp = tables[[2]]
tmp
airline = "http://www.theacsi.org/index.php?option=com_content&view=article&id=147&catid=&Itemid=212&i=Airlines"
airline.table = readHTMLTable(airline, header=T, which=1,stringsAsFactors=F)
View(airline.table)
airline.table = readHTMLTable(airline)
etf.table= readHTMLTable(etf,header=T,which=1,stringsAsFactors=F)
etf
tables = readHTMLTable(u,stringsAsFactors=F)
tables
etf.table= readHTMLTable(etf,stringsAsFactors=F)
etf.table
etf.table= readHTMLTable(etf,which=1,stringsAsFactors=F)
View(etf.table)
etf.table= readHTMLTable(etf,which=2,stringsAsFactors=F)
View(etf.table)
etf.table
install.packages("RCurl")
etf_return = "http://news.morningstar.com/etf/lists/ETFReturns.html?topNum=All&lastRecNum=100000&curField=8&category=0"
etf_return_raw.table = readHTMLTable(etf_return,which=3,stringsAsFactors=F)
funds_return ="http://news.morningstar.com/fund-category-returns"
funds_return_raw.table = readHTMLTable(funds_return,which=1,stringsAsFactors=F)
nr_etf=nrow(etf_return_raw.table) -1
nc_etf=ncol(etf_return_raw.table) -1
library("zoo")
library("fPortfolio")
library("PerformanceAnalytics")
?maxreturnPortfolio
??maxreturnPortfolio
exp(-1)
1 - 0.3678794
exp(-1)
1/(1+exp(-1))
1/(1+exp(1))
exp(1)
setwd("D:/Analytics/Analytics_edge/Logistic_Regression/quality_care")
quality = read.csv("quality.csv")
str(quality)
summary(quality)
table(quality$PoorCare)
install.packages("CaTools")
install.packages("caTools")
library("caTools")
set.seed(88)
split = sample.split(quality$PoorCare,SplitRatio = 0.75)
split
qualityTrain = subset(quality,split==T)
qualityTest = subset(quality,split==F)
str(qualityTrain)
str(qualityTest)
QualityLog = glm(PoorCare ~ OfficeVisits + Narcotics , data = qualityTrain)
summary(qualityLog)
summary(QualityLog)
QualityLog = glm(PoorCare ~ OfficeVisits + Narcotics , data = qualityTrain, family=binomial)
summary(QualityLog)
predictTrain = predict(QualityLog , type = "response")
summary(predictTain)
summary(predictTrain)
tapply(predictTrain , quality$PoorCare , mean)
tapply(predictTrain , qualityTrain$PoorCare , mean)
str(predictTrain)
QualityLog = glm(PoorCare ~ OfficeVisits + Narcotics + StartedOnCombination , data = qualityTrain, family=binomial)
summary(QualityLog)
QualityLog = glm(PoorCare ~ OfficeVisits + Narcotics + StartedOnCombination , data = qualityTrain, family=binomial)
summary(QualityLog)
str(qualityTrain)
## building the logistic regression to include StartedOnCombination
QualityLog = glm(PoorCare ~ ProviderCount + StartedOnCombination , data = qualityTrain, family=binomial)
summary(QualityLog)
table(qualityTrain$PoorCare , predictTrain > 0.5)
10/10+15
table(qualityTrain$PoorCare , predictTrain > 0.7)
table(qualityTrain$PoorCare , predictTrain > 0.2)
20/25
10/25
15/25
15/25
install.packages("ROCR")
library("ROCR")
ROCRpred = prediction(predictTrain , quality$PoorCare)
ROCRpred = prediction(predictTrain , qualityTrain$PoorCare)
ROCRpref = performance(ROCRpred,"tpr","fpr")
plot(ROCRperf)
ROCRpref = performance(ROCRpred , "tpr","fpr")
plot(ROCRperf)
ROCRpred = prediction(predictTrain, qualityTrain$PoorCare)
ROCRperf = performance(ROCRpred, "tpr", "fpr")
plot(ROCRperf)
plot(ROCRperf, colorize=T)
plot(ROCRperf, colorize=T, print.cutoffs.at=seq(0,1,0.1), text.adj=c(-0.2,1.7))
plot(ROCRperf, colorize=T, print.cutoffs.at=seq(0,1,0.1), text.adj=c(-0.2,0.7))
plot(ROCRperf, colorize=T, print.cutoffs.at=seq(0,1,0.1), text.adj=c(-0.2,2.7))
plot(ROCRperf, colorize=T, print.cutoffs.at=seq(0,1,0.1), text.adj=c(-0.2,017))
plot(ROCRperf, colorize=T, print.cutoffs.at=seq(0,1,0.1), text.adj=c(-0.2,1.7))
plot(ROCRperf, colorize=T, print.cutoffs.at=seq(0,1,0.1), text.adj=c(-0.2,0.7))
QualityLog = glm(PoorCare ~ OfficeVisits + Narcotics , data = qualityTrain, family=binomial)
summary(QualityLog)
predictTest = predict(QualityLog , type="response", newdata=qualityTest)
table(qualityTest$PoorCare , predictTest > 0.3)
ROCRpredTest = prediction(predictTest, qualityTest$PoorCare)
ROCRpredTest = prediction(predictTest, qualityTest$PoorCare)
ROCRperf = performance(ROCRpredTest, "tpr", "fpr")
performance(ROCRpredTest, "auc")
auc = as.numeric(performance(ROCRpredTest, "auc")@y.values)
auc
ROCRperf = performance(ROCRpredTest, "tpr", "fpr")
plot(ROCRperf)
ROCRperftest = performance(ROCRpredTest, "tpr", "fpr")
plot(ROCRperftest)
plot(ROCRperf, colorize=TRUE)
plot(ROCRperf, colorize=TRUE, print.cutoffs.at=seq(0,1,by=0.1), text.adj=c(-0.2,1.7))
##
rm(list=ls())
library("zoo")
library("fPortfolio")
##library("PerformanceAnalytics")
library("XML")
library("stringr")
library("tseries")
setwd("D:/Analytics/R-code/portfolio_optimization_prediction")
#
# Build a matrix of market quotes. The fuction returns the quotes as a zoo
# matrix.
# Arguments:
#    symbols- a vector of one or more symbols (character strings)
#    period - d (daily), w (weekly) or m (monthly)
#    startDate - start date in ISO date format (e.g., 2011-12-31)
#    endDate - end date in ISO date format
#
buildQuoteMatrix = function( symbols, period, startDate, endDate)
{
for (i in 1:length(symbols))
{
sym = symbols[i]
print(sprintf("Reading symbol %s from yahoo", sym , i))
ts = get.hist.quote( sym, startDate, endDate, provider="yahoo", compression=period, quote="AdjClose", quiet=T)
if (i == 1) {
quote.mat = ts ## timeseries
} else {
quote.mat = cbind(quote.mat, ts)
}
}
colnames(quote.mat) = symbols
return( quote.mat)
} # buildQuoteMatrix
#
# This function is passed a matrix of returns.  The result is
# the weights, mean return  and standard deviation of the
# global minimum variance portfolio, where the only
# constraint is full investment (e.g., shorting is allowed).
#
analyticGMV = function(returns)
{
S = cov(returns)
Sinv = solve(S)
one = rep(1, ncol(S))
denom = as.numeric(t(one) %*% Sinv %*% one)
w = (Sinv %*% one) / denom
sd = 1 / sqrt(denom)
rslt = list(w = round(t(w), 8), mu = mean(returns %*% w), sd = sd)
return(rslt)
}
#
# Calculate the weights, mean return and standard deviation of the
# tangency portfolio.
#
analyticTangency = function(returns, rf)
{
mu = apply(returns, 2, mean)
S = cov(returns)
Sinv = solve(S)
one = rep(1, ncol(S))
mu_e = mu - rf
w = (Sinv %*% mu_e) / as.numeric((t(one) %*% Sinv %*% mu_e))
sd = sqrt(t(w) %*% S %*% w)
rslt = list(w = round(t(w), 6), mu = sum(w * mu), sd = sd)
return(rslt)
}
#
# Given two Markowitz mean/variance optimized portfolio weights, calculate a set of
# means and 5% CVaR values for the efficient frontier using the "two fund theorm".
# Note that these are not CVaR optimized portfolio.  The CVaR value is calculated
# from the weighted return distribution.
#
meanETLPoints = function(returns, gmv_wts, tan_wts, alpha = seq(from=-0.1, to=1.1, by=0.05))
{
y_mu = list()
x_etl = list()
gmv_wts_t = as.vector(gmv_wts)
tan_wts_t = as.vector(tan_wts)
C = cov(returns)
ix = 1
mu = apply(returns, 2, mean)
for (i in alpha) {
w = i * gmv_wts_t + ((1-i) * tan_wts_t)
y_mu[ix] = mu %*% w
x_etl[ix] = cvarRisk(returns, w)
ix = ix + 1
}
rslt = list(mu=y_mu, etl=x_etl)
return(rslt)
}
#
# Calculate the efficient frontier for CVaR (ETL) optimized portfolios between a mininum mean
# and a maximum mean. This is done by calculating portfolios for a given target return.
#
etlPoints = function(returns.ts, minMu, maxMu )
{
spec = portfolioSpec()
setType(spec) = "CVaR"
constraints = "Short"
setSolver(spec)  = "solveRglpk.CVAR"
nPts = 40
muRange = seq(from=minMu, to=maxMu, by=((maxMu - minMu)/nPts))
mu = list()
etl = list()
for (i in 1:length(muRange)) {
targetMu = muRange[i]
setTargetReturn( spec ) = targetMu
port = efficientPortfolio(data=returns.ts, spec=spec, constraints=constraints)
mu[i] = targetMu
etl[i] = cvarRisk(returns.ts, getWeights(port))
}
rslt = list(mu = mu, etl = etl)
}
etf_return = "http://news.morningstar.com/etf/lists/ETFReturns.html?topNum=All&lastRecNum=100000&curField=8&category=0"
etf_return_raw.table = readHTMLTable(etf_return,which=3,stringsAsFactors=F)
funds_return ="http://news.morningstar.com/fund-category-returns"
funds_return_raw.table = readHTMLTable(funds_return,which=1,stringsAsFactors=F)
colnames(funds_return_raw.table)[1] = "Name" ## remove space from the colname
nr_etf=nrow(etf_return_raw.table) -1
nc_etf=ncol(etf_return_raw.table) -1
## Data cleansing
##etf_return.table= etf_return_raw.table[50:70,]
##etf_return.table=unique(etf_return.table)
etf_return.table= unique(etf_return_raw.table)
etf_return.table=etf_return.table[,2:nc_etf] ## remove blank columns
##etf_return.table=etf_return.table[-(which(is.na(etf_return.table[,1]))),] ## remove rows with NA value
colnames(etf_return.table)=etf_return.table[1,] ## set column names
etf_return.table=na.omit(etf_return.table) ## removing na values from the data frame
colnames(etf_return.table)[2] = "SubCategory" ## renaming the column to sub-category
etf_return.table <- etf_return.table[order(etf_return.table$SubCategory), ] ## sorting by sub category
funds_return.table=unique(funds_return_raw.table[,1:2])
##colnames(funds_return.table) <- sub(" ", "", colnames(funds_return.table)) ## remove spaces from colnames
colnames(funds_return.table)[2] = "onemonth_perc"
## creating a dataframe for category and sub-category
category=data.frame(matrix(NA, nrow = nrow(funds_return.table), ncol = ncol(funds_return.table))) ## creating a dataframe
colnames(category)=c("cat","subcat") ## giving column names
for (i in 1:nrow(funds_return.table))
{
if ( is.na(funds_return.table$onemonth_perc[i]) )
{
categ=funds_return.table$Name[i]
subcateg = ""
}
else
{
subcateg=funds_return.table$Name[i]
}
if (length(subcateg) > 0)
{
category$cat[i]=categ
category$subcat[i]=subcateg
}
}
## Merging to get category column in the dataframe
etf_return.table=merge(etf_return.table,category,by.x="SubCategory", by.y="subcat", all.x=T)
## processing the dataframe to get the symbols
## use str_sub to cut the string from back
## use sub to replace spaces and gsub to replace brackets
##etf_return.table$Symbol=gsub("\\(|\\)", "",sub(" ", "", str_sub(etf_return.table$Name,-6,-1)))
etf_return.table$Symbol=sapply(str_sub(etf_return.table$Name,-6,-1),function(x) str_sub(x,str_locate(x,"\\(")[1] +1,str_length(x)-1) )
## remove rows having category as NA
etf_return.table = na.omit(etf_return.table)
## sorting by category
etf_return.table <- etf_return.table[order(etf_return.table$cat), ] ## sorting by sub category
## correcting symbol for qCN
##etf_return.table$Symbol[11]="CN"
## removing rows for symbol IBDN,IBDM
##etf_return.table=etf_return.table[-152,] ## IBDN
##etf_return.table=etf_return.table[-152,] ## IBDM
##etf_return.table=etf_return.table[-152,] ## IBDK
etf_return.table=etf_return.table[-(which(etf_return.table$TradingVolume==0)),] ## remove all rows having tradingvolume=0
etf_return.table=etf_return.table[-(which(etf_return.table$Symbol=="VLSM")),] ## remove VLSM
etf_return.table=etf_return.table[-(which(etf_return.table$Symbol=="EMSA")),] ## remove EMSA
etf_return.table=etf_return.table[-(which(etf_return.table$Symbol=="MFLA")),] ## remove MFLA
etf_return.table=etf_return.table[-(which(etf_return.table$Symbol=="EFNL")),] ## remove EFNL
etf_return.table=etf_return.table[-which(etf_return.table$Symbol==""),] ## remove blank symbol
colnames(etf_return.table) = gsub("%", "perc",sub(" ", "", colnames(etf_return.table)) )
etf_return.table = etf_return.table[-which(etf_return.table$YTDReturnperc == "---"),]
endDate=Sys.Date() - 1
startDate=Sys.Date() - 90
returnFile="quotes.dat"
rfSym = "^TNX"
# Load the ETF returns object, if the save file exists or write out the save file
if (file.exists(returnFile ) == T)
{
load( returnFile )
} else {
prices.mat = buildQuoteMatrix(etf_return.table$Symbol, period="d", startDate, endDate)
rf.mat = buildQuoteMatrix(rfSym, period="d", startDate, endDate)
rf.mat =  apply(as.matrix(rf.mat),2,function(x) ( (1+x/100)^(1/365) )-1  )
##rfTenYear = weeklyRate(rfSym, startDate, endDate)
##mkt = get.hist.quote( mktSym, startDate, endDate, provider="yahoo", compression="w", quote="AdjClose", quiet=T)
##save(prices.mat, mkt, rfTenYear, file=returnFile)
}
## Quality care logistic Regression
library("caTools")
library("ROCR")
setwd("D:/Analytics/Analytics_edge/Logistic_Regression/quality_care")
ret.mat = returns(as.matrix(prices.mat), type = "discrete",na.rm=T) ## calculating returns data
ret.mat=ret.mat[-1,] ## removing the first row with NA data as no returns calculated
ret.mat[is.na(ret.mat)]=0
rf.mat = rf.mat[-1,]
## create different data frames for each category
df_ret.mat = data.frame(ret.mat)
category = "dummy"
## rm(list = ls(pattern = "\\bdf_"))
j=0
for (i in 1:nrow(etf_return.table))
{
if (category != gsub(" ", "_", etf_return.table$cat[i]) )
{
if  (i > 1)
{
assign(paste("df_cat_", j , sep=""),df_dummy[,-1])
}
category = gsub(" ", "_", etf_return.table$cat[i])
df_dummy = data.frame(rep(category,nrow(ret.mat)) )
df_dummy = cbind(df_dummy,df_ret.mat[etf_return.table$Symbol[i]])
j = j + 1
}
else
{
df_dummy = cbind(df_dummy,df_ret.mat[etf_return.table$Symbol[i]])
}
if (i == nrow(etf_return.table))
{
assign(paste("df_cat_", j , sep=""),df_dummy[,-1])
}
}
cat_ret=matrix(0,nrow(ret.mat))
for (i in 1:length(unique(etf_return.table$cat)) )
{
etf_cat_ret = get(paste("df_cat_", i , sep=""))
cat_ret = cbind(cat_ret,apply(etf_cat_ret,1,mean))
}
cat_ret = cat_ret[,-1] ## to remove first column having 0 value
##geom.mat=(mean.geometric(ret.mat)))
##a=tapply(ret.mat,ret.mat$)
geom.mat = apply(cat_ret,2,function(x) ( (sum(1+x) )^(1/length(which(x != 0)) ) ) -1  )
cat.ret.ts = as.timeSeries(cat_ret)
##ret.mat.ts = as.timeSeries(ret.mat)
spec = portfolioSpec()
setType(spec) = "CVaR"
setSolver(spec)  = "solveRglpk.CVAR"
setRiskFreeRate(spec) = mean(rf.mat)
constraints = "minW[]=0.01"
# Calculate the CVaR (ETL) optimized tangency portfolio weights
pdf("tan.etl.pdf")
tan.etl = tangencyPortfolio(data=cat.ret.ts, spec = spec, constraints = constraints)
dev.off()
# calculate the CVaR (ETL) optimized global minimum variance portfolio weights
pdf("gmv.etl.pdf")
gmv.etl = minvariancePortfolio(data=cat.ret.ts, spec=spec, constraints=constraints)
dev.off()
pdf("tan.etl.pdf")
tan.etl = tangencyPortfolio(data=cat.ret.ts, spec = spec, constraints = constraints)
tan.etl = tangencyPortfolio(data=cat.ret.ts, spec = spec, constraints = constraints)
weightsPlot(tan.etl, labels = TRUE, title = TRUE, mtext = TRUE, box = TRUE, legend = TRUE)
weightsPie(tan.etl)
dev.on()
dev.new
weightsPie(tan.etl)
plot(ROCRperftest)
x11()
weightsPie(tan.etl)
?weightspie
??weightspie
weightsPie(tan.etl,col="yellow")
weightsPie(tan.etl,col=c("yellow","blue","green","red","orange","pink","grey","black") )
weightedReturnsPie(tan.etl,col=c("yellow","blue","green","red","orange","pink","grey","black") )
weightedReturnsPie(tan.etl,col=c("yellow","blue","black","red","orange","pink","grey","green") )
weightedReturnsPie(tan.etl,col=c("yellow","blue","black","red","orange","pink","grey","green"),labels=F )
weightedReturnsPie(tan.etl,col=c("yellow","blue","black","red","orange","pink","grey","green"),labels=T )
framingham = read.csv("framingham.csv")
setwd("D:/Analytics/Analytics_edge/Logistic_Regression/Framingham")
framingham = read.csv("framingham.csv")
str(framingham)
library("caTools")
set.seed(1000)
split = sample.split(framingham$TenYearCHD,SplitRatio = 0.65)
train = subset(quality,split == T)
train = subset(framingham,split == T)
test = subset(framingham,split == F)
str(train)
str(test)
framinghamLog = glm(TenYearCHD ~ ., data=train, family = binomial)
summary(framinghamLog)
predictTest = predict(framinghamLog , type="response" , newdata=test)
summary(predictTest)
table(test$TenYearCHD , predictTest > 0.5)
(1069 + 11)/(1069 + 6 + 11 + 187)
(1069 + 6)/(1069 + 6 + 11 + 187) ## = 0.8483896
ROCRpred = prediction (predictTest , test$TenYearCHD)
auc = as.numeric(performance(ROCRpred, "auc")@y.values)
auc
11/198
1069/1075
